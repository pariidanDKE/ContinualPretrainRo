- eval_batch_size=8
- model_path=meta-llama/Llama-3.2-1B-Instruct
- use_mps=True
- apply_chat_template=true
- tasks_to_run=[]
