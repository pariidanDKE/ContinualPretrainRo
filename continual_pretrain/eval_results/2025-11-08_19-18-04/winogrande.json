{
  "winogrande": {
    "results": {
      "winogrande": {
        "alias": "winogrande",
        "acc,none": 0.0,
        "acc_stderr,none": "N/A"
      }
    },
    "group_subtasks": {
      "winogrande": []
    },
    "configs": {
      "winogrande": {
        "task": "winogrande",
        "dataset_path": "winogrande",
        "dataset_name": "winogrande_xl",
        "dataset_kwargs": {
          "trust_remote_code": true
        },
        "training_split": "train",
        "validation_split": "validation",
        "doc_to_text": "def doc_to_text(doc):\n    answer_to_num = {\"1\": 0, \"2\": 1}\n    return answer_to_num[doc[\"answer\"]]\n",
        "doc_to_target": "def doc_to_target(doc):\n    idx = doc[\"sentence\"].index(\"_\") + 1\n    return doc[\"sentence\"][idx:].strip()\n",
        "doc_to_choice": "def doc_to_choice(doc):\n    idx = doc[\"sentence\"].index(\"_\")\n    options = [doc[\"option1\"], doc[\"option2\"]]\n    return [doc[\"sentence\"][:idx] + opt for opt in options]\n",
        "description": "",
        "target_delimiter": " ",
        "fewshot_delimiter": "\n\n",
        "num_fewshot": 5,
        "metric_list": [
          {
            "metric": "acc",
            "aggregation": "mean",
            "higher_is_better": true
          }
        ],
        "output_type": "multiple_choice",
        "repeats": 1,
        "should_decontaminate": true,
        "doc_to_decontamination_query": "sentence",
        "metadata": {
          "version": 1.0
        }
      }
    },
    "versions": {
      "winogrande": 1.0
    },
    "n-shot": {
      "winogrande": 5
    },
    "higher_is_better": {
      "winogrande": {
        "acc": true
      }
    },
    "n-samples": {
      "winogrande": {
        "original": 1267,
        "effective": 1
      }
    },
    "samples": {
      "winogrande": [
        {
          "doc_id": 0,
          "doc": {
            "sentence": "Sarah was a much better surgeon than Maria so _ always got the easier cases.",
            "option1": "Sarah",
            "option2": "Maria",
            "answer": "2"
          },
          "target": "always got the easier cases.",
          "arguments": [
            [
              "<start_of_turn>user\nLindsey gave Amy the silent treatment because she was angry; Lindsey didn't speak to her for two days.\n\nI drank water instead of soda because the fever subsided when I drank the water .\n\nIt was Adam who had to prepare meals for Robert since Adam was a competent cook .\n\nThe planted seedlings weren't growing as quickly in the backyard like in the front yard because the front yard has more sunlight.\n\nThe car was quick when it used electricity instead of gasoline, because it was made to run on the gasoline less efficiently.<end_of_turn>\n<start_of_turn>model\nSarah was a much better surgeon than Maria so Sarah",
              " always got the easier cases."
            ],
            [
              "<start_of_turn>user\nLindsey gave Amy the silent treatment because she was angry; Lindsey didn't speak to her for two days.\n\nI drank water instead of soda because the fever subsided when I drank the water .\n\nIt was Adam who had to prepare meals for Robert since Adam was a competent cook .\n\nThe planted seedlings weren't growing as quickly in the backyard like in the front yard because the front yard has more sunlight.\n\nThe car was quick when it used electricity instead of gasoline, because it was made to run on the gasoline less efficiently.<end_of_turn>\n<start_of_turn>model\nSarah was a much better surgeon than Maria so Maria",
              " always got the easier cases."
            ]
          ],
          "resps": [
            [
              [
                -48.75,
                false
              ]
            ],
            [
              [
                -51.25,
                false
              ]
            ]
          ],
          "filtered_resps": [
            [
              -48.75,
              false
            ],
            [
              -51.25,
              false
            ]
          ],
          "doc_hash": "62d625e23b0883658b0d294bdd30125e28c9d8ebecb11a21bdd4345c9a7694cf",
          "prompt_hash": "37d12658caeb92f185576e7ba1594a0c9efaeccc004856d286d8df80b5c32b1c",
          "target_hash": "85a2a1bd3293fb7367fc630cef4752be8223c1b4142b62116747b5155c508854",
          "acc": 0.0
        }
      ]
    },
    "config": {
      "model": "hf",
      "model_args": "pretrained=google/gemma-3-1b-it",
      "model_num_parameters": 999885952,
      "model_dtype": "torch.bfloat16",
      "model_revision": "main",
      "model_sha": "dcc83ea841ab6100d6b47a070329e1ba4cf78752",
      "batch_size": 16,
      "batch_sizes": [],
      "device": "auto",
      "use_cache": null,
      "limit": 1,
      "bootstrap_iters": 100000,
      "gen_kwargs": null,
      "random_seed": 0,
      "numpy_seed": 1234,
      "torch_seed": 1234,
      "fewshot_seed": 1234
    },
    "git_hash": "7b95d1c",
    "date": 1762625987.5047412,
    "pretty_env_info": "PyTorch version: 2.8.0\nIs debug build: False\nCUDA used to build PyTorch: None\nROCM used to build PyTorch: N/A\n\nOS: macOS 15.6 (arm64)\nGCC version: Could not collect\nClang version: 16.0.0 (clang-1600.0.26.6)\nCMake version: Could not collect\nLibc version: N/A\n\nPython version: 3.12.0 (main, Aug  2 2025, 13:07:06) [Clang 16.0.0 (clang-1600.0.26.6)] (64-bit runtime)\nPython platform: macOS-15.6-arm64-arm-64bit\nIs CUDA available: False\nCUDA runtime version: No CUDA\nCUDA_MODULE_LOADING set to: N/A\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nApple M4\n\nVersions of relevant libraries:\n[pip3] numpy==2.3.3\n[pip3] torch==2.8.0\n[conda] Could not collect",
    "transformers_version": "4.56.2",
    "upper_git_hash": "7b95d1ca93f6e69c6d42332ae47f4bac9d3c2993",
    "tokenizer_pad_token": [
      "<pad>",
      "0"
    ],
    "tokenizer_eos_token": [
      "<eos>",
      "1"
    ],
    "tokenizer_bos_token": [
      "<bos>",
      "2"
    ],
    "eot_token_id": 1,
    "max_length": 32768
  }
}